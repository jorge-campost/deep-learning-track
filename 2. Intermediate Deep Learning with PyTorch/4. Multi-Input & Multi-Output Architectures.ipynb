{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Multi-Input & Multi-Output Architectures\n",
    "\n",
    "Build multi-input and multi-output models, demonstrating how they can handle tasks requiring more than one input or generating multiple outputs. You will explore how to design and train these models using PyTorch and delve into the crucial topic of loss weighting in multi-output models. This involves understanding how to balance the importance of different tasks when training a model to perform multiple tasks simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-input models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-input dataset\n",
    "\n",
    "Building a multi-input model starts with crafting a custom dataset that can supply all the inputs to the model. In this exercise, you will build the Omniglot dataset that serves triplets consisting of:\n",
    "- The image of a character to be classified,\n",
    "- The one-hot encoded alphabet vector of length 30, with zeros everywhere but for a single one denoting the ID of the alphabet the character comes from,\n",
    "- The target label, an integer between 0 and 963.\n",
    "\n",
    "You are provided with `train_samples`, a list of 3-tuples comprising an image's file path, its alphabet vector, and the target label. Also, the following imports have already been done for you, so let's get to it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "- Assign transform and samples to class attributes with the same names.\n",
    "- Implement the `.__len()__` method such that it return the number of samples stored in the class' samples attribute.\n",
    "- Unpack the sample at index `idx` assigning its contents to `img_path`, `alphabet`, and `label`.\n",
    "- Transform the loaded image with `self.transform()` and assign it to `img_transformed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OmniglotDataset(Dataset):\n",
    "    def __init__(self, transform, samples):\n",
    "        # Assign transform and samples to class attributes\n",
    "        self.transform = transform\n",
    "        self.samples = samples\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return number of samples\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Unpack the sample at index idx\n",
    "        img_path, alphabet, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert(\"L\")\n",
    "        # Transform the image\n",
    "        img_transformed = self.transform(img)\n",
    "        return img_transformed, alphabet, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = OmniglotDataset(\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((64, 64)),\n",
    "        ]\n",
    "    ),\n",
    "    samples=samples,\n",
    ")\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    shuffle=True,\n",
    "    batch_size=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-input model\n",
    "\n",
    "With the data ready, it's time to build the two-input model architecture! To do so, you will set up a model class with the following methods:\n",
    "\n",
    "`.__init__()`, in which you will define sub-networks by grouping layers; this is where you define the two layers for processing the two inputs, and the classifier that returns a classification score for each class.\n",
    "\n",
    "`forward()`, in which you will pass both inputs through corresponding pre-defined sub-networks, concatenate the outputs, and pass them to the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "\n",
    "- Define image, alphabet and classifier sub-networks as sequential models, assigning them to `self.image_layer`, `self.alphabet_layer` and `self.classifier`, respectively.\n",
    "- Pass the image and alphabet through the appropriate model layers.\n",
    "- Concatenate the outputs from image and alphabet layers and assign the result to `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Define sub-networks as sequential models\n",
    "        self.image_layer = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16 * 32 * 32, 128),\n",
    "        )\n",
    "        self.alphabet_layer = nn.Sequential(\n",
    "            nn.Linear(30, 8),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 + 8, 964),\n",
    "        )\n",
    "\n",
    "    def forward(self, x_image, x_alphabet):\n",
    "        # Pass the x_image and x_alphabet through appropriate layers\n",
    "        x_image = self.image_layer(x_image)\n",
    "        x_alphabet = self.alphabet_layer(x_alphabet)\n",
    "        # Concatenate x_image and x_alphabet\n",
    "        x = torch.cat((x_image, x_alphabet), dim=1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-output Dataset and DataLoader\n",
    "\n",
    "In this and the following exercises, you will build a two-output model to predict both the character and the alphabet it comes from based on the character's image. As always, you will start with getting the data ready.\n",
    "\n",
    "The `OmniglotDataset` class you have created before is available for you to use along with updated `samples`. Let's use it to build the Dataset and the DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets\\omniglot_train\\Alphabet_of_the_Magi\\character01\\0709_01.png\n",
      "14400\n"
     ]
    }
   ],
   "source": [
    "root_folder = \"datasets\\\\omniglot_train\"\n",
    "\n",
    "alphabets_folders = os.listdir(root_folder)\n",
    "included_extensions = [\"jpg\", \"jpeg\", \"bmp\", \"png\"]\n",
    "\n",
    "samples = []\n",
    "\n",
    "alphabets_folders = [\n",
    "    os.path.join(root_folder, name)\n",
    "    for name in os.listdir(root_folder)\n",
    "    if os.path.isdir(os.path.join(root_folder, name))\n",
    "]\n",
    "\n",
    "for alphabet_folder in alphabets_folders:\n",
    "    characters_folders = [\n",
    "        os.path.join(alphabet_folder, name)\n",
    "        for name in os.listdir(alphabet_folder)\n",
    "        if os.path.isdir(os.path.join(alphabet_folder, name))\n",
    "    ]\n",
    "\n",
    "    for character_folder in characters_folders:\n",
    "        images_list = [\n",
    "            os.path.join(character_folder, name)\n",
    "            for name in os.listdir(character_folder)\n",
    "            if os.path.isfile(os.path.join(character_folder, name))\n",
    "        ]\n",
    "\n",
    "        images_list = filter(lambda i:any([i.endswith(ext) for ext in included_extensions]), images_list)\n",
    "        samples.extend(images_list)\n",
    "\n",
    "# ('omniglot_train/Gujarati/character45/0462_20.png', 0, 1)\n",
    "print(samples[0])\n",
    "print(len(set(samples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "\n",
    "- Print the element of `samples` at index `100` and examine its structure.\n",
    "- Use your `OmniglotDataset` to create `dataset_train`, passing the two image transforms you have used before: parse the image to a tensor and resize it to size `(64, 64)`.\n",
    "- Create `dataloader_train` from `dataset_train`; shuffle the training images and set batch size to `32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the sample at index 100\n",
    "print(samples[100])\n",
    "\n",
    "# Create dataset_train\n",
    "dataset_train = OmniglotDataset(\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((64, 64)),\n",
    "        ]\n",
    "    ),\n",
    "    samples=samples,\n",
    ")\n",
    "\n",
    "# Create dataloader_train\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-output model architecture\n",
    "\n",
    "In this exercise, you will construct a multi-output neural network architecture capable of predicting the character and the alphabet.\n",
    "\n",
    "Recall the general structure: in the `.__init__()` method, you define layers to be used in the forward pass later. In the `forward()` method, you will first pass the input image through a couple of layers to obtain its embedding, which in turn is fed into two separate classifier layers, one for each output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "\n",
    "- Define `self.classifier_alpha` and `self.classifier_char` as linear layers with input shapes matching the output of `image_layer`, and output shapes corresponding to the number of alphabets (`30`) and the number of characters (`964`), respectively.\n",
    "- Pass the image embedding `x_image` separately through each of the classifiers, assigning the results to `output_alpha` and `output_char`, respectively, and return them in this order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.image_layer = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16 * 32 * 32, 128),\n",
    "        )\n",
    "        # Define the two classifier layers\n",
    "        self.classifier_alpha = nn.Linear(128, 30)\n",
    "        self.classifier_char = nn.Linear(128, 964)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_image = self.image_layer(x)\n",
    "        # Pass x_image through the classifiers and return both results\n",
    "        output_alpha = self.classifier_alpha(x_image)\n",
    "        output_char = self.classifier_char(x_image)\n",
    "        return output_alpha, output_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training multi-output models\n",
    "\n",
    "When training models with multiple outputs, it is crucial to ensure that the loss function is defined correctly.\n",
    "\n",
    "In this case, the model produces two outputs: predictions for the alphabet and the character. For each of these, there are corresponding ground truth labels, which will allow you to calculate two separate losses: one incurred from incorrect alphabet classifications, and the other from incorrect character classification. Since in both cases you are dealing with a multi-label classification task, the Cross-Entropy loss can be applied each time.\n",
    "\n",
    "Gradient descent can optimize only one loss function, however. You will thus define the total loss as the sum of alphabet and character losses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "\n",
    "- Calculate the alphabet classification loss and assign it to `loss_alpha`.\n",
    "- Calculate the character classification loss and assign it to `loss_char`.\n",
    "- Compute the total loss as the sum of the two partial losses and assign it to `loss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.05)\n",
    "\n",
    "for epoch in range(1):\n",
    "    for images, labels_alpha, labels_char in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs_alpha, outputs_char = net(images)\n",
    "        # Compute alphabet classification loss\n",
    "        loss_alpha = criterion(outputs_alpha, labels_alpha)\n",
    "        # Compute character classification loss\n",
    "        loss_char = criterion(outputs_char, labels_char)\n",
    "        # Compute total loss\n",
    "        loss = loss_alpha + loss_char\n",
    "        # loss = ((1 - char_weight) * loss_alpha) + (char_weight * loss_char)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of multi-output models and loss weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-output model evaluation\n",
    "\n",
    "In this exercise, you will practice model evaluation for multi-output models. Your task is to write a function called `evaluate_model()` that takes an alphabet-and-character-predicting model as input, runs the evaluation loop, and prints the model's accuracy in the two tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "\n",
    "- Define `acc_alpha` and `acc_char` as multi-class `Accuracy()` metrics for the two outputs, alphabets and characters, with the appropriate number of classes each (there are `30` alphabets and `964` characters in the dataset).\n",
    "- Define the evaluation loop by iterating over test `images`, `labels_alpha`, and `labels_char`.\n",
    "- Inside the for-loop, obtain model results for the test data batch and assign them to `outputs_alpha`, `outputs_char`.\n",
    "- Update the two accuracy metrics with the current batch's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    # Define accuracy metrics\n",
    "    acc_alpha = Accuracy(task=\"multiclass\", num_classes=30)\n",
    "    acc_char = Accuracy(task=\"multiclass\", num_classes=964)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels_alpha, labels_char in dataloader_test:\n",
    "            # Obtain model outputs\n",
    "            outputs_alpha, outputs_char = model(images)\n",
    "            _, pred_alpha = torch.max(outputs_alpha, 1)\n",
    "            _, pred_char = torch.max(outputs_char, 1)\n",
    "            # Update both accuracy metrics\n",
    "            acc_alpha(pred_alpha, labels_alpha)\n",
    "            acc_char(pred_char, labels_char)\n",
    "\n",
    "    print(f\"Alphabet: {acc_alpha.compute()}\")\n",
    "    print(f\"Character: {acc_char.compute()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-track-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
